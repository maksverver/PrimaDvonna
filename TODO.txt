Note for after test competition 4:
 - Timing code has changed yet again. check if the online judge is still 70~90ms
   behind my expected time. If not, up the time limit to e.g. 4.95 or so.

For test competition 4:
  - maybe: remove `pass' as dfs() parameter?
  - better handling of 'exact' values; if these are stored in the tt, their
    depth should be considered infinite.
  - large benchmark to determine if `depth - 1` or `depth` works better when
    only one move is available.
  - get rid of EXTERN nonsense? (also in compile.pl!) (benchmark if it helps)

  - review hashing code:
     - Zobrist hashing seems to give more collissions (need stats!)
     - maybe FNV is better because fewer positions are evaluated?
     - how can I test on a Pentium IV?


For test competition 5:
  - negascout?
  - improve setup function (borrow for Dvonner?)

For test competition 6:
  - improve evaluation function (how?)

For final version:
  - change compile.pl to #define NDEBUG so assertions are not tested anymore?

Later:
 - consider move representation:
    - maybe ints instead of chars is more efficient?
    - change library functions so single moves are passed by value?
      (how to benchmark these changes when evaluation takes most time?)
 - include some benchmarks and run them on the Codecup server, tweaking various
   parameters?

Maybe later:
 - represent moves as two ints (source, destination?)
 - include principal variation in AI result.
 - consider implementing NegaScout? (should work well with killer heuristic?)
 - consider implementing  MTD(f)? (tricky with float values)
 - make board hashing for TT more efficient, if possible.
 - check hash table performance:
     - how often do collisions occur?
     - how full is the table when they happen?
     - reconsider replacement policy (replace if depth >= tt->depth only?)
 - try to optimize time budget for moves
 - validate all code!
     - print it out, verify, add comments...
 - consider auto-learning for evaluation parameters?
   See: http://www.littlegolem.net/jsp/forum/topic2.jsp?forum=30&topic=19
   Note: this is what Dvonner did!
 - test against Rororobot and Jan's Program on littlegolem.net

Overall:
 - improve placement phase evaluation function
 - improve stacking phase evaluation function
 - improve move ordering heuristic:
    - to evaluate: take a random sample of positions, rank possible moves by
      value, and see which ones tend to be good?
