TODO soon:
   - do a full competition between Holtz, Dvonner, dDvonn and my player.
   - use the results above to compare set-up functions
     (see "Interesting Experiment" below)

Next match:
   - GOAL: beat Dvonner/Holtz/dDvonn consistently!

   - Note: dDvonn uses different search algorithms/evaluation functions
     depending on wheter it's playing white or black. Pit these against each
     other to find out which works best?

   - Possible evaluation function tweaks:
      - change weights of moves (3/4/5 e.g. to 2/4/6 e.g. to 1/1/1)
      - instead of returning (a - b), return 100*(a - b)/(a + b)
        (after all, the relative difference in moves is more imporant than
         the absolute difference)

Interesting experiment:
 - Play against Dvonner. If I lose, truncate the game to 49 moves, and have
   Dvonner player against itself. If Dvonner loses in my position too, then
   apparently Dvonner's phase 1 algorithm is better than mine. If Dvonner loses
   with less discs difference, then its phase 2 algorithm is better too.
   
   Manual experiments seem to confirm both of these, but I need to perform a
   lot more experiments to get statistically reliable results! (Automate the
   process and then run for a 1000 games or so, alternating between white and
   black?)

Note on timing:
 - Codecup server seems to think I take more time than I thought I did!
   Difference seems to be <= 0.250s so I'll aim at using max. 4.75s for now.
   IMPORTANT: check results for next match too, to see what the maximum
   difference there is, and adjust the margin accordingly!

Later:
 - consider implementing NegaScout? (should work well with killer heuristic?)
 - remove `best' as dfs() parameter? (then, how to shuffle moves?)
 - remove `pass' as dfs() parameter? (are there positions where we benefit from it?)
 - test if current move representation is inefficient (ints instead of chars?)
 - change library functions so single moves are passed by value.
 - smarter move ordering: capture moves first, etc?
 - shuffle moves when depth >= 2 or so? (shuffling seemed to improve cut-offs)
 - make board hashing for TT more efficient
 - check hash table performance: how often do collisions occur?
   how full is the table when they happen?
 - optimize time budget for moves
 - implement MTD(f)?
 - validate all code!
 - consider auto-learning for evaluation parameters?
   See: http://www.littlegolem.net/jsp/forum/topic2.jsp?forum=30&topic=19
 - test against Rororobot and Jan's Program on littlegolem.net
 - reconsider tt replacement policy (replace if depth >= tt->depth only?)

Long time:
 - improve placement phase evaluation function
 - improve stacking phase evaluation function
 - improve move ordering heuristic:
    - to evaluate: take a random sample of positions, rank possible moves by
      value, and see which ones tend to be good?
 - benchmark code, find bottlenecks, fix them.

Test suite:
 - transposition table tests: check values for various positions with and
   without tt, and ensure their values are equal.
 - collect various positions; benchmark and validate player with different
   techniques enabled?
